{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow import profiler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.experimental.stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CIFAR-10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to arrays\n",
    "y_train = y_train[:, 0]\n",
    "y_test = y_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one hot\n",
    "z_train = np.zeros((y_train.shape[0], 10))\n",
    "z_train[np.arange(z_train.shape[0]), y_train] = 1\n",
    "\n",
    "z_test = np.zeros((y_test.shape[0], 10))\n",
    "z_test[np.arange(z_test.shape[0]), y_test] = 1\n",
    "\n",
    "y_train, y_test = z_train, z_test\n",
    "del z_train, z_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(data, dtype='float32'):\n",
    "    # luma coding weighted average in video systems\n",
    "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
    "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
    "    # add channel dimension\n",
    "    rst = np.expand_dims(rst, axis=3)\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = grayscale(X_train)\n",
    "X_test = grayscale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (50000, 32, 32, 1)\n",
      "y_train (50000, 10)\n",
      "X_test (10000, 32, 32, 1)\n",
      "y_test (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Labels according to the index\n",
    "Labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# 50000 images of 32x32 size with 3 channels\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "\n",
    "# 10000 images of 32x32 size with 3 channels\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "plt.title(Labels[y_train[index].argmax()])\n",
    "plt.imshow(X_train[index], cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Retina + VVS Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(ret_channels, vvs_layers):\n",
    "    \"\"\"\n",
    "    This function returns a keras model given the number of output channels for the Retina-Net\n",
    "    and the number of convolutional layers of the VVS-Net\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retina Network\n",
    "    inputs = keras.layers.Input((32, 32, 1))\n",
    "    ret_conv1 = keras.layers.Conv2D(32, (9, 9), padding=\"same\", activation='relu')(inputs)\n",
    "    ret_bn1 = keras.layers.BatchNormalization()(ret_conv1)\n",
    "    ret_conv2 = keras.layers.Conv2D(ret_channels, (9, 9), padding=\"same\", activation=\"relu\")(ret_bn1)\n",
    "    ret_bn2 = keras.layers.BatchNormalization()(ret_conv2)\n",
    "    \n",
    "    # VVS-Network\n",
    "    vvs_bn = ret_bn2\n",
    "    for _ in range(vvs_layers):\n",
    "        vvs_conv = keras.layers.Conv2D(32, (9, 9), padding=\"same\", activation=\"relu\")(vvs_bn)\n",
    "        vvs_bn = keras.layers.BatchNormalization()(vvs_conv)\n",
    "    vvs_flatten = keras.layers.Flatten()(vvs_bn)\n",
    "    vvs_fc1 = keras.layers.Dense(1024, activation=\"relu\")(vvs_flatten)\n",
    "    outputs = keras.layers.Dense(10, activation=\"softmax\")(vvs_fc1)\n",
    "    \n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "batch_size = 128\n",
    "ret_channels = 32\n",
    "vvs_layers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        82976     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        82976     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        82976     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        82976     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        82976     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 33,983,978\n",
      "Trainable params: 33,983,594\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = define_model(ret_channels=ret_channels, vvs_layers=vvs_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=[\"accuracy\", keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"Retina:{ret_channels}|VVS:{vvs_layers}|BatchSize:{batch_size}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "TB = keras.callbacks.TensorBoard(\"tf_logs/\" + name, write_images=True)\n",
    "\n",
    "# Early Stopping\n",
    "ES = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=2, mode=\"min\")\n",
    "\n",
    "# Model Checkpoint\n",
    "MC = keras.callbacks.ModelCheckpoint(\"models/\" + name + \".h5\", save_best_only=True, monitor=\"val_loss\",\n",
    "                                     mode=\"min\")\n",
    "\n",
    "# Reduce LR on Plateau\n",
    "LR = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/313 [..............................] - ETA: 0s - loss: 3.1782 - accuracy: 0.0625 - auc: 0.5056WARNING:tensorflow:From /home/gilbertocunha/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "313/313 [==============================] - 576s 2s/step - loss: 2.2627 - accuracy: 0.3200 - auc: 0.7717 - val_loss: 2.5325 - val_accuracy: 0.2049 - val_auc: 0.6762\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 566s 2s/step - loss: 1.5442 - accuracy: 0.4411 - auc: 0.8604 - val_loss: 1.7818 - val_accuracy: 0.3844 - val_auc: 0.8240\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 560s 2s/step - loss: 1.3021 - accuracy: 0.5399 - auc: 0.9024 - val_loss: 1.4518 - val_accuracy: 0.5040 - val_auc: 0.8846\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 587s 2s/step - loss: 1.1195 - accuracy: 0.6078 - auc: 0.9283 - val_loss: 1.2196 - val_accuracy: 0.5766 - val_auc: 0.9170\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 591s 2s/step - loss: 0.9883 - accuracy: 0.6564 - auc: 0.9438 - val_loss: 1.1529 - val_accuracy: 0.6132 - val_auc: 0.9253\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 594s 2s/step - loss: 0.8741 - accuracy: 0.6962 - auc: 0.9558 - val_loss: 0.9940 - val_accuracy: 0.6644 - val_auc: 0.9441\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 592s 2s/step - loss: 0.7749 - accuracy: 0.7311 - auc: 0.9648 - val_loss: 1.1853 - val_accuracy: 0.6267 - val_auc: 0.9237\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 579s 2s/step - loss: 0.6765 - accuracy: 0.7645 - auc: 0.9728 - val_loss: 1.1749 - val_accuracy: 0.6360 - val_auc: 0.9280\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 582s 2s/step - loss: 0.5962 - accuracy: 0.7908 - auc: 0.9785 - val_loss: 1.0681 - val_accuracy: 0.6800 - val_auc: 0.9411\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 570s 2s/step - loss: 0.5058 - accuracy: 0.8249 - auc: 0.9839 - val_loss: 1.1929 - val_accuracy: 0.6631 - val_auc: 0.9299\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 561s 2s/step - loss: 0.4331 - accuracy: 0.8486 - auc: 0.9880 - val_loss: 1.2345 - val_accuracy: 0.6724 - val_auc: 0.9297\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 564s 2s/step - loss: 0.3609 - accuracy: 0.8749 - auc: 0.9913 - val_loss: 1.3128 - val_accuracy: 0.6617 - val_auc: 0.9238\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 575s 2s/step - loss: 0.2925 - accuracy: 0.8984 - auc: 0.9939 - val_loss: 1.5005 - val_accuracy: 0.6496 - val_auc: 0.9142\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 597s 2s/step - loss: 0.2540 - accuracy: 0.9123 - auc: 0.9949 - val_loss: 1.6349 - val_accuracy: 0.6494 - val_auc: 0.9100\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 593s 2s/step - loss: 0.1208 - accuracy: 0.9609 - auc: 0.9989 - val_loss: 1.2643 - val_accuracy: 0.7165 - val_auc: 0.9331\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 589s 2s/step - loss: 0.0673 - accuracy: 0.9827 - auc: 0.9997 - val_loss: 1.2946 - val_accuracy: 0.7148 - val_auc: 0.9324\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 570s 2s/step - loss: 0.0521 - accuracy: 0.9877 - auc: 0.9998 - val_loss: 1.3271 - val_accuracy: 0.7204 - val_auc: 0.9311\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 564s 2s/step - loss: 0.0422 - accuracy: 0.9904 - auc: 0.9999 - val_loss: 1.3605 - val_accuracy: 0.7189 - val_auc: 0.9297\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 568s 2s/step - loss: 0.0347 - accuracy: 0.9932 - auc: 0.9999 - val_loss: 1.3949 - val_accuracy: 0.7203 - val_auc: 0.9283\n",
      "Epoch 20/100\n",
      "107/313 [=========>....................] - ETA: 5:57 - loss: 0.0305 - accuracy: 0.9942 - auc: 0.9999"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-16-932d1e875a29>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m model.fit(X_train, y_train, batch_size=batch_size, validation_split=0.2, \n\u001B[0m\u001B[1;32m      2\u001B[0m           epochs=100, callbacks=[TB, ES, MC, LR], shuffle=True)\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    106\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 108\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m     \u001B[0;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1096\u001B[0m                 batch_size=batch_size):\n\u001B[1;32m   1097\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1098\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1099\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1100\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    778\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    779\u001B[0m         \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 780\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    781\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    782\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    805\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    806\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 807\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    808\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    809\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2827\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2828\u001B[0m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2829\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2830\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2831\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_filtered_call\u001B[0;34m(self, args, kwargs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1841\u001B[0m       \u001B[0;31m`\u001B[0m\u001B[0margs\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1842\u001B[0m     \"\"\"\n\u001B[0;32m-> 1843\u001B[0;31m     return self._call_flat(\n\u001B[0m\u001B[1;32m   1844\u001B[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001B[1;32m   1845\u001B[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1921\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1922\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1923\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1924\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1925\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    543\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    544\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 545\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    546\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    547\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, validation_split=0.2,\n",
    "          epochs=100, callbacks=[TB, ES, MC, LR], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}